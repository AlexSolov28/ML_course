# -*- coding: utf-8 -*-
"""Lab_2_TMO.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12Ar_-SzSGJVKVdMH6VsAbhld5S0HQIob

# Лабораторная работа №2

## Обработка пропусков в данных, кодирование категориальных признаков, масштабирование данных.

### Задание:

1. Выбрать набор данных (датасет), содержащий категориальные признаки и пропуски в данных. Для выполнения следующих пунктов можно использовать несколько различных наборов данных (один для обработки пропусков, другой для категориальных признаков и т.д.)
2. Для выбранного датасета (датасетов) на основе материалов лекции решить следующие задачи:
   * обработку пропусков в данных;
   * кодирование категориальных признаков;
   * масштабирование данных.
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline
sns.set(style="ticks")

"""### Загрузка и первичный анализ данных"""

# Будем использовать только обучающую выборку
data = pd.read_csv('qs-world-university-rankings-2017-to-2022-V2.csv')

# размер набора данных
data.shape

# типы колонок
data.dtypes

# проверим есть ли пропущенные значения
data.isnull().sum()

# Первые 5 строк датасета
data.head()

total_count = data.shape[0]
print('Всего строк: {}'.format(total_count))

"""### Обработка пропусков в данных"""

# Удаление колонок, содержащих пустые значения
data_new_1 = data.dropna(axis=1, how='any')
(data.shape, data_new_1.shape)

# Удаление строк, содержащих пустые значения
data_new_2 = data.dropna(axis=0, how='any')
(data.shape, data_new_2.shape)

data.head()

# Заполнение всех пропущенных значений нулями
# В данном случае это некорректно, так как нулями заполняются в том числе категориальные колонки
data_new_3 = data.fillna(0)
data_new_3.head()

"""### Обработка пропусков и числовых данных"""

# Выберем числовые колонки с пропущенными значениями
# Цикл по колонкам датасета
num_cols = []
for col in data.columns:
    # Количество пустых значений
    temp_null_count = data[data[col].isnull()].shape[0]
    dt = str(data[col].dtype)
    if temp_null_count>0 and (dt=='float64' or dt=='int64'):
        num_cols.append(col)
        temp_perc = round((temp_null_count / total_count) * 100.0, 2)
        print('Колонка {}. Тип данных {}. Количество пустых значений {}, {}%.'.format(col, dt, temp_null_count, temp_perc))

# Фильтр по колонкам с пропущенными значениями
data_num = data[num_cols]
data_num

# Гистограмма по признакам
for col in data_num:
    plt.hist(data[col], 50)
    plt.xlabel(col)
    plt.show()

"""### Обработка пропусков в категориальных данных"""

# Выберем категориальные колонки с пропущенными значениями
# Цикл по колонкам датасета
cat_cols = []
for col in data.columns:
    # Количество пустых значений
    temp_null_count = data[data[col].isnull()].shape[0]
    dt = str(data[col].dtype)
    if temp_null_count>0 and (dt=='object'):
        cat_cols.append(col)
        temp_perc = round((temp_null_count / total_count) * 100.0, 2)
        print('Колонка {}. Тип данных {}. Количество пустых значений {}, {}%.'.format(col, dt, temp_null_count, temp_perc))

cat_temp_data = data[['research_output']]
cat_temp_data.head()

cat_temp_data['research_output'].unique()

cat_temp_data[cat_temp_data['research_output'].isnull()].shape

from sklearn.impute import SimpleImputer
from sklearn.impute import MissingIndicator

# Импьютация наиболее частыми значениями
imp2 = SimpleImputer(missing_values=np.nan, strategy='most_frequent')
data_imp2 = imp2.fit_transform(cat_temp_data)
data_imp2

# Пустые значения отсутствуют
np.unique(data_imp2)

# Импьютация константой
imp3 = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value='NA')
data_imp3 = imp3.fit_transform(cat_temp_data)
data_imp3

np.unique(data_imp3)

data_imp3[data_imp3=='NA'].size

"""### Преобразование категориальных признаков в числовые"""

cat_enc = pd.DataFrame({'c1':data_imp2.T[0]})
cat_enc

"""### Кодирование категорий целочисленными значениями
Использование LabelEncoder
"""

from sklearn.preprocessing import LabelEncoder

cat_enc['c1'].unique()

le = LabelEncoder()
cat_enc_le = le.fit_transform(cat_enc['c1'])

# Наименования категорий в соответствии с порядковыми номерами

# Свойство называется classes, потому что предполагается что мы решаем
# задачу классификации и каждое значение категории соответствует
# какому-либо классу целевого признака

le.classes_

cat_enc_le

np.unique(cat_enc_le)

# В этом примере видно, что перед кодированием
# уникальные значения признака сортируются в лексикографиеском порядке
le.inverse_transform([0, 1, 2, 3])

"""Использование OrdinalEncoder"""

from sklearn.preprocessing import OrdinalEncoder

data_oe = data[['rank_display', 'faculty_count', 'type']]
data_oe.head()

imp4 = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value='NA')
data_oe_filled = imp4.fit_transform(data_oe)
data_oe_filled

oe = OrdinalEncoder()
cat_enc_oe = oe.fit_transform(data_oe_filled)
cat_enc_oe

"""### Кодирование категорий наборами бинарных значений
В этом случае каждое уникальное значение признака становится новым отдельным признаком.
"""

from sklearn.preprocessing import OneHotEncoder

ohe = OneHotEncoder()
cat_enc_ohe = ohe.fit_transform(cat_enc[['c1']])

cat_enc.shape

cat_enc_ohe.shape

cat_enc_ohe

cat_enc_ohe.todense()[0:10]

cat_enc.head(10)

"""### Pandas get_dummies - быстрый вариант one-hot кодирования"""

pd.get_dummies(cat_enc).head()

pd.get_dummies(cat_temp_data, dummy_na=True).head()

"""### Масштабирование данных
Масштабирование предполагает изменение диапазона измерения величины, а нормализация - изменение распределения этой величины.

MinMax масштабирование
"""

from sklearn.preprocessing import MinMaxScaler, StandardScaler, Normalizer

sc1 = MinMaxScaler()
sc1_data = sc1.fit_transform(data[['score']])

plt.hist(data['score'], 50)
plt.show()

plt.hist(sc1_data, 50)
plt.show()

"""### Масштабирование данных на основе Z-оценки - StandardScaler"""

sc2 = StandardScaler()
sc2_data = sc2.fit_transform(data[['score']])

plt.hist(sc2_data, 50)
plt.show()

